{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: Developing your Zomato business account and profile is a great way to boost your restaurant’s online reputation\n",
      "DocID: 41, Score: 0.185878\n",
      "DocID: 34, Score: 0.101136\n",
      "DocID: 17, Score: 0.060491\n",
      "DocID: 14, Score: 0.059895\n",
      "DocID: 40, Score: 0.052352\n",
      "DocID: 26, Score: 0.048949\n",
      "DocID: 30, Score: 0.043797\n",
      "DocID: 39, Score: 0.034275\n",
      "DocID: 35, Score: 0.034162\n",
      "DocID: 36, Score: 0.033587\n",
      "--------------------------------------------------\n",
      "Query 2: Warwickshire, came from an ancient family and was the heiress to some land\n",
      "DocID: 29, Score: 0.107435\n",
      "DocID: 16, Score: 0.026933\n",
      "DocID: 1, Score: 0.021333\n",
      "DocID: 20, Score: 0.020221\n",
      "DocID: 13, Score: 0.016643\n",
      "DocID: 41, Score: 0.015930\n",
      "DocID: 6, Score: 0.015060\n",
      "DocID: 27, Score: 0.013712\n",
      "DocID: 30, Score: 0.012880\n",
      "DocID: 36, Score: 0.011273\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "# Preprocessing: normalize, case folding, remove punctuation, and tokenize\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # case folding\n",
    "    text = re.sub(r\"\\W+\", \" \", text)  # remove punctuation\n",
    "    tokens = text.split()  # tokenize by space\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Build the inverted index with document frequencies and term frequencies\n",
    "def build_index(corpus_dir):\n",
    "    index = defaultdict(list)  # term -> postings (docID, term frequency)\n",
    "    doc_lengths = {}  # docID -> document length (for normalization)\n",
    "    N = 0  # total number of documents\n",
    "\n",
    "    for docID, filename in enumerate(os.listdir(corpus_dir), 1):\n",
    "        N += 1\n",
    "        with open(os.path.join(corpus_dir, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "            tokens = preprocess(content)\n",
    "            term_freqs = Counter(tokens)\n",
    "            doc_length = 0\n",
    "\n",
    "            for term, freq in term_freqs.items():\n",
    "                log_tf = 1 + math.log10(freq)  # log(tf) for documents\n",
    "                index[term].append((docID, log_tf))\n",
    "                doc_length += log_tf**2\n",
    "\n",
    "            doc_lengths[docID] = math.sqrt(\n",
    "                doc_length\n",
    "            )  # store the length for normalization\n",
    "\n",
    "    return index, doc_lengths, N\n",
    "\n",
    "\n",
    "# Calculate the tf-idf scores for the query\n",
    "def compute_query_tfidf(query, index, N):\n",
    "    query_tokens = preprocess(query)\n",
    "    query_term_freqs = Counter(query_tokens)\n",
    "    query_tfidf = {}\n",
    "    query_length = 0\n",
    "\n",
    "    for term, freq in query_term_freqs.items():\n",
    "        if term in index:\n",
    "            df = len(index[term])\n",
    "            idf = math.log10(N / df)  # log(N/df) for queries\n",
    "            log_tf = 1 + math.log10(freq)  # log(tf) for queries\n",
    "            query_tfidf[term] = log_tf * idf  # tf-idf for query\n",
    "            query_length += (log_tf * idf) ** 2\n",
    "\n",
    "    query_length = math.sqrt(query_length)  # query normalization\n",
    "    return query_tfidf, query_length\n",
    "\n",
    "\n",
    "# Compute cosine similarity between query and documents\n",
    "def cosine_similarity(query_tfidf, query_length, index, doc_lengths):\n",
    "    doc_scores = defaultdict(float)\n",
    "\n",
    "    for term, query_weight in query_tfidf.items():\n",
    "        if term in index:\n",
    "            for docID, doc_weight in index[term]:\n",
    "                doc_scores[docID] += query_weight * doc_weight\n",
    "\n",
    "    # Normalize by document lengths\n",
    "    for docID in doc_scores:\n",
    "        doc_scores[docID] /= query_length * doc_lengths[docID]\n",
    "\n",
    "    return sorted(\n",
    "        doc_scores.items(), key=lambda x: (-x[1], x[0])\n",
    "    )  # sort by score and docID\n",
    "\n",
    "\n",
    "# Search function to process queries and return top 10 relevant documents\n",
    "def search(query, index, doc_lengths, N):\n",
    "    query_tfidf, query_length = compute_query_tfidf(query, index, N)\n",
    "    ranked_docs = cosine_similarity(query_tfidf, query_length, index, doc_lengths)\n",
    "    return ranked_docs[:10]  # return top 10 results\n",
    "\n",
    "\n",
    "# Load and index the corpus\n",
    "corpus_dir = \"corpus\"  # change this to your corpus directory\n",
    "index, doc_lengths, N = build_index(corpus_dir)\n",
    "\n",
    "# Test queries\n",
    "queries = [\n",
    "    \"Developing your Zomato business account and profile is a great way to boost your restaurant’s online reputation\",\n",
    "    \"Warwickshire, came from an ancient family and was the heiress to some land\",\n",
    "]\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"Query {i}: {query}\")\n",
    "    results = search(query, index, doc_lengths, N)\n",
    "    for docID, score in results:\n",
    "        print(f\"DocID: {docID}, Score: {score:.6f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
